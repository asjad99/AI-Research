# Spark's DataFrame API




## Filtering: 

Basic Filtering: 
```
df.filter(df.age > 3).show()
```

Basic filtering SQL Style

```
df.filter("age > 3").show()
```

Filtering row values of a particular column Based on entries in a python list

``` 
agri_df.filter((agri_df["Country"]).isin(List1)).show()
```
Example:

```
# define a list of scores
l = [10,18,20]

# include only records with these scores in list l
df.filter(df.score.isin(l))

# filter out records by scores by list l
records = df.filter(~df.score.isin(l))
```

**Broadcasting for Efficiency:**

If the Python list is relatively small compared to the DataFrame, you can broadcast the list to all Spark nodes to make filtering more efficient. 

```
from pyspark.sql.functions import broadcast

df_filtered = df[df["studentID"].isin(broadcast(studentID_list))]

# Show filtered DataFrame
df_filtered.show()
```


#### Multiple Filtering 

```
display(s_transcript_df.filter('studentid = "1" AND Term = "5233"'))
```

```

studentID_list = ["1", "2", "3"]  # Replace these IDs with the ones you're interested in

# Filtering the DataFrame based on the condition that 'studentid' should be in studentID_list and 'Term' should be "5233"
filtered_df = s_transcript_df.filter(
    F.col("studentid").isin(studentID_list) &  # Checks if 'studentid' is in the list
    F.col("Term") == "5233"  # Checks if 'Term' is "5233"
)

filtered_df.show()

``` 


#### Viewing Output: 



```
results.show(false) , results will not be truncated 
```

```
df.persist
df.show(df.count, false) // in Scala or 'False' in Python
```


#### Group-By 
